{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.3.2\n",
      " GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# import the general stuff\n",
    "import os\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "#import stuff for gradCAM\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import Image\n",
    "\n",
    "#Set GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#import the tf stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Check TensorFlow Version\n",
    "print('TF version: {}' .format(tf.__version__))\n",
    "\n",
    "#Check for GPU utilization\n",
    "if tf.test.gpu_device_name():\n",
    "    print(' GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              134218752 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 148,934,465\n",
      "Trainable params: 148,934,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#set Image size (RGB so imshape is 3)\n",
    "pix_dim = 512\n",
    "imsize = (pix_dim,pix_dim) \n",
    "imshape = (pix_dim,pix_dim,3)\n",
    "\n",
    "#load model\n",
    "filepath = './models/VGG16_model_4_8020split_512px'\n",
    "model = tf.keras.models.load_model(filepath, compile = True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = \"block5_pool\"\n",
    "classifier_layer_names = [\n",
    "    \"flatten_1\",\n",
    "    \"dense_2\",\n",
    "    \"dropout_1\",\n",
    "    \"dense_3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of images names\n",
    "\n",
    "def get_image_list(hxpath):\n",
    "    labels = []\n",
    "    for img in os.listdir(hxpath):\n",
    "        #pull the name of the image\n",
    "        labels.append(img)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image \n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size = imsize)\n",
    "    # `array` is a float32 Numpy array \n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, X, X, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(\n",
    "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
    "):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = tf.keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "        \n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "    \n",
    "    #grads = tape.gradient(bottom_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "def make_gradcam_images(hxpath, GCfolderpath):\n",
    "    \n",
    "    #get the list of labels\n",
    "    labels = get_image_list(hxpath)\n",
    "\n",
    "    for ip in labels: \n",
    "        impath = str(hxpath) + str(ip)\n",
    "        img = tf.keras.preprocessing.image.load_img(impath,target_size = imsize)\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img/255\n",
    "        img_array = np.expand_dims(img,axis=0)\n",
    "\n",
    "\n",
    "        # Generate class activation heatmap\n",
    "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names)\n",
    "\n",
    "        # We load the original image\n",
    "        Orimg = tf.keras.preprocessing.image.load_img(impath, target_size = imsize)\n",
    "        Orimg = tf.keras.preprocessing.image.img_to_array(Orimg)\n",
    "\n",
    "        # We rescale heatmap to a range 0-255\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "        # We use jet colormap to colorize heatmap\n",
    "        vir = cm.get_cmap(\"viridis\")\n",
    "\n",
    "        # We use RGB values of the colormap\n",
    "        vir_colors = vir(np.arange(256))[:, :3]\n",
    "        vir_heatmap = vir_colors[heatmap]\n",
    "\n",
    "        # We create an image with RGB colorized heatmap\n",
    "        vir_heatmap = tf.keras.preprocessing.image.array_to_img(vir_heatmap)\n",
    "        vir_heatmapI = vir_heatmap.resize((Orimg.shape[1], Orimg.shape[0]))\n",
    "        vir_heatmap = tf.keras.preprocessing.image.img_to_array(vir_heatmapI)\n",
    "\n",
    "        # Superimpose the heatmap on original image\n",
    "        superimposed_img = vir_heatmap * 0.4 + Orimg\n",
    "        superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "        #save\n",
    "        superimposed_img = superimposed_img.save(GCfolderpath + ip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-abc1a3fd6958>:61: RuntimeWarning: invalid value encountered in true_divide\n",
      "  heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n"
     ]
    }
   ],
   "source": [
    "#CALL THE FUNCTION AND MAKE THE IMAGES\n",
    "make_gradcam_images('../data/pics/raw/Isaias_20200804a_jpgs/','../data/pics/gradcam/Model4/I_GCimages/')\n",
    "make_gradcam_images('../data/pics/raw/Florence_20180917a_jpgs/','../data/pics/gradcam/Model4/F_GCimages/')\n",
    "make_gradcam_images('../data/pics/raw/Michael_20181011a_jpgs/','../data/pics/gradcam/Model4/M_GCimages/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# import the general stuff\n",
    "import os\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "#import stuff for gradCAM\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import Image\n",
    "\n",
    "#Set GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#import the tf stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Check TensorFlow Version\n",
    "print('TF version: {}' .format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Check for GPU utilization\n",
    "if tf.test.gpu_device_name():\n",
    "    print(' GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2741 images belonging to 2 classes.\n",
      "Found 684 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#build data generators for training and validaton\n",
    "\n",
    "split = 0.2\n",
    "\n",
    "# Define dirs and files\n",
    "train_data_dir = '../data/pics/labelertoModel/AllRoundsSeven'\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator and split data\n",
    "train_datagen = ImageDataGenerator(rescale =1./255.,\n",
    "                                   rotation_range = 90,\n",
    "                                   width_shift_range = 0.5,\n",
    "                                   height_shift_range = 0.5,\n",
    "                                   shear_range = 0.45,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = True,\n",
    "                                   validation_split = split)\n",
    "\n",
    "\n",
    "#set batch Size\n",
    "batch_size = 16\n",
    "\n",
    "#set Image size (RGB so imshape is 3)\n",
    "pix_dim = 512\n",
    "imsize = (pix_dim,pix_dim) \n",
    "imshape = (pix_dim,pix_dim,3)\n",
    "\n",
    "# Flow training images in batches \n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = imsize,\n",
    "                                                    subset='training')\n",
    "\n",
    "# Flow validation images in batches \n",
    "validation_generator =  train_datagen.flow_from_directory(train_data_dir, # same directory as training data,\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        class_mode = 'binary',\n",
    "                                                        target_size = imsize,\n",
    "                                                        subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = 2741\n",
    "total_val = 684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the metrics\n",
    "acc_metric = tf.keras.metrics.BinaryAccuracy(name='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 256, 256, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 128, 128, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 128, 128, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 128, 128, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 128, 128, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 128, 128, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 128, 128, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 64, 64, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 64, 64, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 64, 64, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 64, 64, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 64, 64, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 32, 32, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 32, 32, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 32, 32, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 32, 32, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 32, 32, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 32, 32, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 512)  524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 16, 16, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 16, 16, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 16, 16, 2048) 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 16, 16, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 16, 16, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 16, 16, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 16, 16, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 16, 16, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 16, 16, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 16, 16, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 16, 16, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 16, 16, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 16, 16, 2048) 0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load or build model\n",
    "##########\n",
    "\n",
    "#from scratch:\n",
    "#base model, no top layer, w/ imagenet weights\n",
    "base_model = tf.keras.applications.ResNet50(input_shape = imshape, \n",
    "                                             include_top = False, \n",
    "                                             weights = None)\n",
    "\n",
    "# to freeze the batch Norm layers\n",
    "#base_model.training = False\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 256, 256, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 128, 128, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 128, 128, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 128, 128, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 128, 128, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 128, 128, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 128, 128, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 64, 64, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 64, 64, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 64, 64, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 64, 64, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 64, 64, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 32, 32, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 32, 32, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 32, 32, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 32, 32, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 32, 32, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 32, 32, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 512)  524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 16, 16, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 16, 16, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 16, 16, 2048) 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 16, 16, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 16, 16, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 16, 16, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 16, 16, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 16, 16, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 16, 16, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 16, 16, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 16, 16, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 16, 16, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 16, 16, 2048) 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add a new classifcation layer\n",
    "final_layer = base_model.get_layer('conv5_block3_out')\n",
    "#print('shape of last layer is ', final_layer.output_shape)\n",
    "final_base_output = final_layer.output\n",
    "\n",
    "# add avg pool\n",
    "x = layers.GlobalAveragePooling2D(name='avg_pool')(final_base_output)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)   \n",
    "\n",
    "      \n",
    "#make the model trainable (even though the batch norm layers are frowqzen from Training = False)\n",
    "#base_model.trainable = True\n",
    "\n",
    "model = Model(base_model.input, x) \n",
    "#############\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #LR determination\n",
    "# callbacks = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch/10))\n",
    "\n",
    "# # #build the model\n",
    "# model.compile(loss = 'binary_crossentropy',\n",
    "#               optimizer = tf.keras.optimizers.RMSprop(lr = 1e-8),\n",
    "#               metrics = acc_metric)\n",
    "\n",
    "# #train the model\n",
    "# history = model.fit(train_generator,\n",
    "#                     steps_per_epoch = total_train // batch_size,\n",
    "#                     #validation_data = validation_generator,\n",
    "#                     epochs= 100,\n",
    "#                     #validation_steps =  total_val // batch_size,\n",
    "#                     workers = 24,\n",
    "#                     callbacks =[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss (y) as a fn of RMSprop Learning rate (x)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #plot the loss curve\n",
    "# lrs  = 1e-8 * (10 ** (np.arange(100) / 10))\n",
    "# plt.semilogx(lrs, history.history[\"loss\"])\n",
    "# plt.axis([1e-8, 10, 0, 10])\n",
    "# plt.title('Loss (y) as a fn of RMSprop Learning rate (x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a callback\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', \n",
    "                                             patience = 20, \n",
    "                                             restore_best_weights = True)\n",
    "\n",
    "#build the model\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr = 1e-5),\n",
    "              metrics = acc_metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "171/171 [==============================] - 109s 635ms/step - loss: 0.6669 - acc: 0.5982 - val_loss: 0.7024 - val_acc: 0.4003\n",
      "Epoch 2/100\n",
      "171/171 [==============================] - 103s 602ms/step - loss: 0.6361 - acc: 0.6341 - val_loss: 0.8007 - val_acc: 0.4807\n",
      "Epoch 3/100\n",
      "171/171 [==============================] - 105s 616ms/step - loss: 0.6091 - acc: 0.6719 - val_loss: 0.9000 - val_acc: 0.4092\n",
      "Epoch 4/100\n",
      "171/171 [==============================] - 102s 598ms/step - loss: 0.5996 - acc: 0.6811 - val_loss: 0.8897 - val_acc: 0.5312\n",
      "Epoch 5/100\n",
      "171/171 [==============================] - 104s 610ms/step - loss: 0.6057 - acc: 0.6745 - val_loss: 0.8842 - val_acc: 0.4955\n",
      "Epoch 6/100\n",
      "171/171 [==============================] - 103s 603ms/step - loss: 0.5879 - acc: 0.6862 - val_loss: 0.9165 - val_acc: 0.5699\n",
      "Epoch 7/100\n",
      "171/171 [==============================] - 103s 602ms/step - loss: 0.5676 - acc: 0.6983 - val_loss: 1.3344 - val_acc: 0.5372\n",
      "Epoch 8/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.5740 - acc: 0.7108"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch = total_train // batch_size,\n",
    "                    validation_data = validation_generator,\n",
    "                    epochs= 100,\n",
    "                    validation_steps =  total_val // batch_size,\n",
    "                    workers = 24,\n",
    "                    callbacks =[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the metrics from training\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r--', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b--', label='Validation loss')\n",
    "plt.title('Training and validation loss') \n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "filepath = './models/VGG16_model_7_8020split_512px_resnet50'\n",
    "model.save(filepath)\n",
    "\n",
    "#load model\n",
    "#model = tf.keras.models.load_model(filepath, compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
